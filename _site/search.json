[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R4DSA Meetup",
    "section": "",
    "text": "This website contains the materials use in current and past R4DSA Meet-up Sessions"
  },
  {
    "objectID": "nov2022/TidyModels1.html",
    "href": "nov2022/TidyModels1.html",
    "title": "Randomisation Inference Statistics: infer methods",
    "section": "",
    "text": "In ISSS602 Data Analytics Lab, we shared with you a collection of conventional inference statistical methods such as two-sample mean test, ANOVA test and Chi-square test, just to name a few of them. These methods are very popular and their use is widespread, but this does not mean they are always the best tool for doing confirmatory data analysis on business and market research data.\nFigure below shows that there is indeed another alternative approach to perform confirmatory data analysis called randomisation inference (Enclosed with blue in the flow diagram).\n\nNote: The subsequent explanation draw extensively from A blog by Allen Downey entitle There is still only one test\nDifferent from conventional inference statistical test whereby given a dataset, we will compute a test statistic that measures the size of the apparent effect. For example, if we are describing a difference between two groups, the test statistic might be the absolute difference in means.\nWe will then formulate a null hypothesis, which is a model of the world under the assumption that the effect is not real; for example, if we think there might be a difference between two groups, the null hypothesis would assume that there is no difference.\nNext, we will compute a p-value, which is the probability of seeing an effect as big asùõøunder the null hypothesis.\nOn the other hand, if randomisation inference test approach is used, we will estimate the p-value by using our model of the null hypothesis to generate many simulated datasets. For each simulated dataset, we will compute the same test statistic we used on the actual data. Finally, we will count the fraction of times the test statistic from simulated data exceedsùõø. This fraction approximates the p-value. If it‚Äôs sufficiently small, we can conclude that the apparent effect is unlikely to be due to chance.\nFor more detail discussion of randomisation inference statistics, please refer to Chapter 11-22 of Introduction to Modern Statistics or Chapter 2-4 of Introductory Statistic with Randomization and Simulation"
  },
  {
    "objectID": "nov2022/TidyModels1.html#enter-infer-a-tidy-inference-statistics",
    "href": "nov2022/TidyModels1.html#enter-infer-a-tidy-inference-statistics",
    "title": "Randomisation Inference Statistics: infer methods",
    "section": "Enter infer: A tidy inference statistics",
    "text": "Enter infer: A tidy inference statistics\nIn the nutshell, infer is an R package specially designed for data analyst to perform randomisation inference statistics by using an expressive statistical grammar that coheres with the tidyverse design framework.\nFigure below shows the five main verbs of infer package. They are:\n\nspecify() allows us to specify the variable, or relationship between variables, that you‚Äôre interested in.\nhypothesize() allows us to declare the null hypothesis.\ngenerate() allows us to generate data reflecting the null hypothesis.\ncalculate() allows us to calculate a distribution of statistics from the generated data to form the null distribution.\nvisualise() allows us to visualize the distribution of the simulation-based inferential statistics or the theoretical distribution (or both!)."
  },
  {
    "objectID": "nov2022/TidyModels1.html#the-data",
    "href": "nov2022/TidyModels1.html#the-data",
    "title": "Randomisation Inference Statistics: infer methods",
    "section": "The Data",
    "text": "The Data\nFor the purpose of this hands-on, a data set called Exam_data.csv will be used\nFigure below shows the content of the data. It consists of seven fields. They are:\n\n\n\n\n\n\n\n\nField Name\nDescription\nData type\n\n\n\n\nID\nUnique ID of student\nString\n\n\nCLASS\nClass level\nString\n\n\nGENDER\nGender of the student (i.e.¬†Female, Male)\nString\n\n\nRACE\nRace of student (i.e.¬†Chinese, Indian, Malay and others)\nString\n\n\nENGLISH\nEnglish scores\nNumeric\n\n\nMATHS\nMaths scores\nNumeric\n\n\nSCIENCE\nScience scores\nNumeric"
  },
  {
    "objectID": "nov2022/TidyModels1.html#installing-and-loading-packages",
    "href": "nov2022/TidyModels1.html#installing-and-loading-packages",
    "title": "Randomisation Inference Statistics: infer methods",
    "section": "Installing and Loading Packages",
    "text": "Installing and Loading Packages\nIn this hands-on exercise, three R packages will be used. They are:\n\nreadr for importing the csv file.\nggplot2 for visualising the data.\ninfer for performing randomisation inference statistics.\n\nHowever, instead of loading them one-by-one by using library(), p_load() of pacman package is used.\n\npacman::p_load(tidyverse, infer)\n\nAlso note that instead of loading readr and ggplot2, tidyverse is loaded. This is because tidyverse will load all the core tidyverse packages that include readr and ggplot2.\n\nImporting data\nIn the code chunk below, read_csv() of readr is used to import Exam_data.csv into R environment and save it as a tibble data frame.\n\nexam <- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nexam\n\n# A tibble: 322 √ó 7\n   ID         CLASS GENDER RACE    ENGLISH MATHS SCIENCE\n   <chr>      <chr> <chr>  <chr>     <dbl> <dbl>   <dbl>\n 1 Student321 3I    Male   Malay        21     9      15\n 2 Student305 3I    Female Malay        24    22      16\n 3 Student289 3H    Male   Chinese      26    16      16\n 4 Student227 3F    Male   Chinese      27    77      31\n 5 Student318 3I    Male   Malay        27    11      25\n 6 Student306 3I    Female Malay        31    16      16\n 7 Student313 3I    Male   Chinese      31    21      25\n 8 Student316 3I    Male   Malay        31    18      27\n 9 Student312 3I    Male   Malay        33    19      15\n10 Student297 3H    Male   Indian       34    49      37\n# ‚Ä¶ with 312 more rows"
  },
  {
    "objectID": "nov2022/TidyModels1.html#eda",
    "href": "nov2022/TidyModels1.html#eda",
    "title": "Randomisation Inference Statistics: infer methods",
    "section": "EDA",
    "text": "EDA\nIn the code chunk below, ggplot2 is used to plot a boxplot with the mean values of both female and male students on their respective boxplots.\n\nggplot(data=exam, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  stat_summary(geom = \"point\",\n               fun.y=\"mean\",\n               colour =\"red\",\n               size=4) +\n  labs(y = \"Maths scores\")\n\nWarning: The `fun.y` argument of `stat_summary()` is deprecated as of ggplot2 3.3.0.\n‚Ñπ Please use the `fun` argument instead.\n\n\n\n\n\nThe boxplot reveals that the mean Maths score of female students is slightly higer than the male students.\n\nSummary statistics\nTo verify our observation, the code chunk below is used to derive the summary statistics of maths score by gender.\n\nexam %>% \n  group_by(GENDER) %>% \n  summarize(n = n(), \n            mean_score = mean(MATHS), \n            std_dev = sd(MATHS))\n\n# A tibble: 2 √ó 4\n  GENDER     n mean_score std_dev\n  <chr>  <int>      <dbl>   <dbl>\n1 Female   170       70.0    18.7\n2 Male     152       68.6    21.4\n\n\nThing to learn from the code chunk above:\n\ngroup_by() and summarize() of dplyr package is used to derive the summary statistics. This is why it is always useful to load the core packages of tidyverse because we can use them anytime we need them."
  },
  {
    "objectID": "nov2022/TidyModels1.html#two-sample-mean-test-with-randomisation-inference-statistics-infer-method",
    "href": "nov2022/TidyModels1.html#two-sample-mean-test-with-randomisation-inference-statistics-infer-method",
    "title": "Randomisation Inference Statistics: infer methods",
    "section": "Two-sample Mean Test with Randomisation Inference Statistics: infer method",
    "text": "Two-sample Mean Test with Randomisation Inference Statistics: infer method\nWith reference to the EDA and summary statistics analysis, the following hypothesis are formulated.\nH0: There is no difference between the mean maths score of female and male students\nH1: The mean maths scores of female and male students are different.\nFor the purpose of this student, 95% confident interval will be used.\n\nspecify variables\nIn the code chunk below, specify() of infer package is used to define the formula and response and explanatory variables.\n\nexam %>% \n  specify(formula = MATHS ~ GENDER)\n\nResponse: MATHS (numeric)\nExplanatory: GENDER (factor)\n# A tibble: 322 √ó 2\n   MATHS GENDER\n   <dbl> <fct> \n 1     9 Male  \n 2    22 Female\n 3    16 Male  \n 4    77 Male  \n 5    11 Male  \n 6    16 Female\n 7    21 Male  \n 8    18 Male  \n 9    19 Male  \n10    49 Male  \n# ‚Ä¶ with 312 more rows\n\n\nThings to learn from the code chunk above:\n\nthe input must be in tibble data frame format.\nthe response variable is maths score.\nthe explanatory variable is gender.\n\n\n\nhypothesize the null\nFor the purpose of this case study, We set the null hypothesis \\(H0: \\hatŒº_f‚àí\\hatŒº_m = 0\\) by using the hypothesize() infer package. Since we have two samples, female and male students, we set null to be \"independence\" as we described in Section 9.3.\n\nexam %>% \n  specify(formula = MATHS ~ GENDER) %>% \n  hypothesize(null = \"independence\")\n\nResponse: MATHS (numeric)\nExplanatory: GENDER (factor)\nNull Hypothesis: independence\n# A tibble: 322 √ó 2\n   MATHS GENDER\n   <dbl> <fct> \n 1     9 Male  \n 2    22 Female\n 3    16 Male  \n 4    77 Male  \n 5    11 Male  \n 6    16 Female\n 7    21 Male  \n 8    18 Male  \n 9    19 Male  \n10    49 Male  \n# ‚Ä¶ with 312 more rows\n\n\nThings to learn from the code chunk above:\n\nWe set this null hypothesis H0 in our infer workflow using the null argument of the hypothesize() function independence for hypotheses involving two samples. If the hypotheses involving a single sample, then point should be used.\nThe data has not changed yet. This will occur at the upcoming generate() step; we‚Äôre merely setting meta-data for now.\n\n\n\ngenerate replicates\nAfter we hypothesize() the null hypothesis, we generate() replicates of ‚Äúshuffled‚Äù datasets assuming the null hypothesis is true. We do this by repeating the shuffling exercise several times. The type argument determines the method used to create the null distribution. They are three types of rendomisation/permutation methods available. They are:\n\nbootstrap: A bootstrap sample will be drawn for each replicate, where a sample of size equal to the input sample size is drawn (with replacement) from the input sample data.\npermute: For each replicate, each input value will be randomly reassigned (without replacement) to a new output value in the sample.\ndraw: A value will be sampled from a theoretical distribution with parameter p specified in hypothesize() for each replicate. This option is currently only applicable for testing on one proportion. This generation type was previously called simulate, which has been superseded.\n\nIn the code chunk below, we replicates the data 1000 times by using permute method.\n\nset.seed(1234)\nexam_permute <- exam %>% \n  specify(formula = MATHS ~ GENDER) %>% \n  hypothesize(null = \"independence\") %>% \n  generate(reps = 1000, type = \"permute\")\nexam_permute\n\nResponse: MATHS (numeric)\nExplanatory: GENDER (factor)\nNull Hypothesis: independence\n# A tibble: 322,000 √ó 3\n# Groups:   replicate [1,000]\n   MATHS GENDER replicate\n   <dbl> <fct>      <int>\n 1    97 Male           1\n 2    64 Female         1\n 3    66 Male           1\n 4    63 Male           1\n 5    58 Male           1\n 6    74 Female         1\n 7    68 Male           1\n 8    88 Male           1\n 9    47 Male           1\n10    87 Male           1\n# ‚Ä¶ with 321,990 more rows\n\n\nThing to learn from the code chunk above.\n\nset.seed() is used to ensure that the ramdomisation is reproducible.\n\nNote that the resulting data frame has 322,000 rows. This is because we performed permutations for each of the 322 rows 1000 times and 322,000 = 322 x 1000. If you explore the exam_permute data frame with View(), you‚Äôll notice that the variable replicate indicates which resample each row belongs to. So it has the value 1 322 times, the value 2 322 times, all the way through to the value 1000 322 times.\n\n\ncalculate summary statistics\nNow, we are going to calculate the appropriate summary statistic for each of our 1000 shuffles by using calculate() of infer package. stat argument of calculate() will be used to specify the summary statistic used.\nIn the code chunk below, ‚Äúdiff in means‚Äù is used.\n\nset.seed(1234)\nnull_distribution_maths <- exam %>% \n  specify(formula = MATHS ~ GENDER) %>% \n  hypothesize(null = \"independence\") %>% \n  generate(reps = 1000, type = \"permute\") %>%\n  calculate(stat = \"diff in means\", \n            order = c(\"Female\", \"Male\"))\nnull_distribution_maths\n\nResponse: MATHS (numeric)\nExplanatory: GENDER (factor)\nNull Hypothesis: independence\n# A tibble: 1,000 √ó 2\n   replicate   stat\n       <int>  <dbl>\n 1         1 -6.12 \n 2         2  3.12 \n 3         3 -4.13 \n 4         4 -6.67 \n 5         5  1.46 \n 6         6 -1.35 \n 7         7  0.467\n 8         8  1.64 \n 9         9 -1.99 \n10        10  1.64 \n# ‚Ä¶ with 990 more rows\n\n\nNote that we have 1000 values of stat, each representing one instance of \\(H0: \\hatŒº_f‚àí\\hatŒº_m = 0\\) in a hypothesized world of no gender difference in maths scores. Observe as well that we chose the name of this data frame carefully: null_distribution.\nWhat was the observed difference in promotion rates? In other words, what was the observed test statistic \\(H0: \\hatŒº_f‚àí\\hatŒº_m = 0\\). In the code chunk below, we compute this value using the previous infer code but with the hypothesize() and generate() steps removed.\n\nobs_diff_means <- exam %>% \n  specify(formula = MATHS ~ GENDER) %>% \n  calculate(stat = \"diff in means\", \n            order = c(\"Female\", \"Male\"))\nobs_diff_means\n\nResponse: MATHS (numeric)\nExplanatory: GENDER (factor)\n# A tibble: 1 √ó 1\n   stat\n  <dbl>\n1  1.40\n\n\n\n\nvisualize the p-value\nFinally, it comes the verdict or more popularly known as statistical conclusion. In this step, we want to measure how surprised we are by a promotion difference of 1.402012 in a hypothesized universe of there are not different between the maths scores of female and male students. If the observed difference of 1.402012 is highly unlikely, then we would be inclined to reject the validity of our hypothesized universe.\nIn the code chunk below,\n\nvisualise() is used to plot the null distribution of our 1000 values of ,\nshade_p_value() function with obs_stat argument set to the observed test statistic value we saved in obs_diff_mean.\n\n\nvisualize(null_distribution_maths, \n          bins = 10) + \n  shade_p_value(obs_stat = obs_diff_means,\n                direction = \"both\")\n\n\n\n\nWith reference to the figure above, the solid dark red line marks 1.402012. However, what does the shaded-region correspond to? This is the p-value. Recall the definition of the p\n\np-value is the probability of obtaining a test statistic just as or more extreme than the observed test statistic assuming the null hypothesis H0 is true.\n\nSo judging by the shaded region in the figure above, it seems that the p-value is larger than the 0.05 critical values. Hence, we failed to reject this hypothesized universe, or using statistical language we ‚Äúdo not have sufficient statistical evident to reject the null hypothesis‚Äù.\nOftentimes, we would like to find out what fraction of the null distribution is shaded? In other words, what is the exact value of the p-value? In the code chunk below, get_p_value() function with the same arguments as the previous shade_p_value() is used to derive the answer for this question.\n\nnull_distribution_maths %>% \n  get_p_value(obs_stat = obs_diff_means,\n              direction = \"both\")\n\n# A tibble: 1 √ó 1\n  p_value\n    <dbl>\n1   0.496\n\n\nKeeping the definition of a p-value in mind, the probability of observing a difference in mean maths score between female and male students as large as 1.402012 due to sampling variation alone in the null distribution is 0.59 = 59%. Since this p-value is larger than our pre-specified significance level Œ± = 0.05, we failed to reject the null hypothesis \\(H0: \\hatŒº_f‚àí\\hatŒº_m = 0\\). In other words, this p-value is not sufficiently small to reject our hypothesised universe of the mean maths scores of female and male students are the same. In conclusion, we do not have enough statistical evidence to change our mind in favor of the mean maths scores of female and male students are not the same."
  },
  {
    "objectID": "nov2022/TidyModels1.html#confident-interval",
    "href": "nov2022/TidyModels1.html#confident-interval",
    "title": "Randomisation Inference Statistics: infer methods",
    "section": "Confident interval",
    "text": "Confident interval\nIn this section, you will learn how to use functions provide by infer package to perform confident interval\n\nexam %>% \n  specify(response = MATHS) %>% \n  calculate(stat = \"mean\")\n\nResponse: MATHS (numeric)\n# A tibble: 1 √ó 1\n   stat\n  <dbl>\n1  69.3\n\n\nspecify variables\n\nexam %>% \n  specify(response = MATHS)\n\nResponse: MATHS (numeric)\n# A tibble: 322 √ó 1\n   MATHS\n   <dbl>\n 1     9\n 2    22\n 3    16\n 4    77\n 5    11\n 6    16\n 7    21\n 8    18\n 9    19\n10    49\n# ‚Ä¶ with 312 more rows\n\n\n\nexam %>% \n  specify(formula = MATHS ~ NULL)\n\nResponse: MATHS (numeric)\n# A tibble: 322 √ó 1\n   MATHS\n   <dbl>\n 1     9\n 2    22\n 3    16\n 4    77\n 5    11\n 6    16\n 7    21\n 8    18\n 9    19\n10    49\n# ‚Ä¶ with 312 more rows\n\n\ngenerate replicates\n\nexam %>% \n  specify(response = MATHS) %>% \n  generate(reps = 1000, type = \"bootstrap\")\n\nResponse: MATHS (numeric)\n# A tibble: 322,000 √ó 2\n# Groups:   replicate [1,000]\n   replicate MATHS\n       <int> <dbl>\n 1         1    66\n 2         1    63\n 3         1    88\n 4         1    79\n 5         1    85\n 6         1    85\n 7         1    77\n 8         1    85\n 9         1    69\n10         1    85\n# ‚Ä¶ with 321,990 more rows\n\n\ncalculate summary statistics\n\nbootstrap_distribution <- exam %>% \n  specify(response = MATHS) %>% \n  generate(reps = 1000) %>% \n  calculate(stat = \"mean\")\n\nSetting `type = \"bootstrap\"` in `generate()`.\n\nbootstrap_distribution\n\nResponse: MATHS (numeric)\n# A tibble: 1,000 √ó 2\n   replicate  stat\n       <int> <dbl>\n 1         1  68.4\n 2         2  68.4\n 3         3  68.8\n 4         4  69.9\n 5         5  71.0\n 6         6  70.0\n 7         7  69.7\n 8         8  69.8\n 9         9  68.9\n10        10  69.2\n# ‚Ä¶ with 990 more rows\n\n\nvisualize the results\n\nvisualize(bootstrap_distribution)\n\n\n\n\n\npercentile_ci <- bootstrap_distribution %>% \n  get_confidence_interval(level = 0.95, type = \"percentile\")\npercentile_ci\n\n# A tibble: 1 √ó 2\n  lower_ci upper_ci\n     <dbl>    <dbl>\n1     67.1     71.5\n\n\n\nvisualize(bootstrap_distribution) + \n  shade_confidence_interval(endpoints = percentile_ci)\n\n\n\n\n\nstandard_error_ci <- bootstrap_distribution %>%  \n  get_confidence_interval(type = \"se\", point_estimate = x_bar)"
  },
  {
    "objectID": "nov2022/TidyModels1.html#reference",
    "href": "nov2022/TidyModels1.html#reference",
    "title": "Randomisation Inference Statistics: infer methods",
    "section": "Reference",
    "text": "Reference\n\nRandomisation Inferential Statistics\n\nThere is still only one test\nIntroduction to Modern Statistics Chapter 11-22.\nIntroductory Statistic with Randomization and Simulation Chapter 2-4.\n\n\n\ninfer\nrstudio::conf 2018 infer: a package for tidy statistical inference"
  }
]