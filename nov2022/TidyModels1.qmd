---
title: "Randomisation Inference Statistics: infer methods"
editor: visual
---

## Overview

In ISSS602 Data Analytics Lab, we shared with you a collection of conventional inference statistical methods such as two-sample mean test, ANOVA test and Chi-square test, just to name a few of them. These methods are very popular and their use is widespread, but this does not mean they are always the best tool for doing confirmatory data analysis on business and market research data.

Figure below shows that there is indeed another alternative approach to perform confirmatory data analysis called **randomisation inference** (Enclosed with blue in the flow diagram).

![](img/image1-0.jpg)

Note: The subsequent explanation draw extensively from A blog by Allen Downey entitle [There is still only one test](http://allendowney.blogspot.com/2016/06/there-is-still-only-one-test.html)

Different from conventional inference statistical test whereby given a dataset, we will compute a test statistic that measures the size of the apparent effect. For example, if we are describing a difference between two groups, the test statistic might be the absolute difference in means.

We will then formulate a null hypothesis, which is a model of the world under the assumption that the effect is not real; for example, if we think there might be a difference between two groups, the null hypothesis would assume that there is no difference.

Next, we will compute a p-value, which is the probability of seeing an effect as big asùõøunder the null hypothesis.

On the other hand, if randomisation inference test approach is used, we will estimate the p-value by using our model of the null hypothesis to generate many simulated datasets. For each simulated dataset, we will compute the same test statistic we used on the actual data. Finally, we will count the fraction of times the test statistic from simulated data exceedsùõø. This fraction approximates the p-value. If it's sufficiently small, we can conclude that the apparent effect is unlikely to be due to chance.

For more detail discussion of randomisation inference statistics, please refer to Chapter 11-22 of [Introduction to Modern Statistics](https://openintro-ims.netlify.app/index.html) or Chapter 2-4 of [Introductory Statistic with Randomization and Simulation](https://openintro-ims.netlify.app/)

## Enter infer: A tidy inference statistics

In the nutshell, [infer](https://infer.netlify.app/index.html) is an R package specially designed for data analyst to perform randomisation inference statistics by using an expressive statistical grammar that coheres with the tidyverse design framework.

Figure below shows the five main verbs of infer package. They are:

-   `specify()` allows us to specify the variable, or relationship between variables, that you're interested in.
-   `hypothesize()` allows us to declare the null hypothesis.
-   `generate()` allows us to generate data reflecting the null hypothesis.
-   `calculate()` allows us to calculate a distribution of statistics from the generated data to form the null distribution.
-   `visualise()` allows us to visualize the distribution of the simulation-based inferential statistics or the theoretical distribution (or both!).

![](img/image1-3.jpg)

## The Data

For the purpose of this hands-on, a data set called Exam_data.csv will be used

Figure below shows the content of the data. It consists of seven fields. They are:

| Field Name | Description                                              | Data type |
|-----------------------|-------------------------|-------------------------|
| ID         | Unique ID of student                                     | String    |
| CLASS      | Class level                                              | String    |
| GENDER     | Gender of the student (i.e. Female, Male)                | String    |
| RACE       | Race of student (i.e. Chinese, Indian, Malay and others) | String    |
| ENGLISH    | English scores                                           | Numeric   |
| MATHS      | Maths scores                                             | Numeric   |
| SCIENCE    | Science scores                                           | Numeric   |

## Installing and Loading Packages

In this hands-on exercise, three R packages will be used. They are:

-   readr for importing the csv file.
-   ggplot2 for visualising the data.
-   infer for performing randomisation inference statistics.

However, instead of loading them one-by-one by using `library()`, `p_load()` of [**pacman**](https://github.com/trinker/pacman) package is used.

```{r}
pacman::p_load(tidyverse, infer)
```

Also note that instead of loading readr and ggplot2, tidyverse is loaded. This is because tidyverse will load all the [core tidyverse](https://www.tidyverse.org/packages/) packages that include readr and ggplot2.

### Importing data

In the code chunk below, read_csv() of readr is used to import Exam_data.csv into R environment and save it as a tibble data frame.

```{r}
exam <- read_csv("data/Exam_data.csv")
exam
```

## EDA

In the code chunk below, ggplot2 is used to plot a boxplot with the mean values of both female and male students on their respective boxplots.

```{r}
ggplot(data=exam, 
       aes(y = MATHS, x= GENDER)) +
  geom_boxplot() +
  stat_summary(geom = "point",
               fun.y="mean",
               colour ="red",
               size=4) +
  labs(y = "Maths scores")
```

The boxplot reveals that the mean Maths score of female students is slightly higer than the male students.

### Summary statistics

To verify our observation, the code chunk below is used to derive the summary statistics of maths score by gender.

```{r}
exam %>% 
  group_by(GENDER) %>% 
  summarize(n = n(), 
            mean_score = mean(MATHS), 
            std_dev = sd(MATHS))
```

Thing to learn from the code chunk above:

-   `group_by()` and `summarize()` of dplyr package is used to derive the summary statistics. This is why it is always useful to load the core packages of tidyverse because we can use them anytime we need them.

## Two-sample Mean Test with Randomisation Inference Statistics: infer method

With reference to the EDA and summary statistics analysis, the following hypothesis are formulated.

H0: There is no difference between the mean maths score of female and male students

H1: The mean maths scores of female and male students are different.

For the purpose of this student, 95% confident interval will be used.

### `specify` variables

In the code chunk below, [`specify()`](https://infer.netlify.app/reference/specify.html) of **infer** package is used to define the formula and response and explanatory variables.

```{r}
exam %>% 
  specify(formula = MATHS ~ GENDER)
```

Things to learn from the code chunk above:

-   the input must be in tibble data frame format.
-   the response variable is maths score.
-   the explanatory variable is gender.

### `hypothesize` the null

For the purpose of this case study, We set the null hypothesis $H0: \hatŒº_f‚àí\hatŒº_m = 0$ by using the [`hypothesize()`](https://infer.netlify.app/reference/hypothesize.html) infer package. Since we have two samples, female and male students, we set `null` to be `"independence"` as we described in Section [9.3](https://moderndive.com/9-hypothesis-testing.html#ht-infer).

```{r}
exam %>% 
  specify(formula = MATHS ~ GENDER) %>% 
  hypothesize(null = "independence")
```

Things to learn from the code chunk above:

-   We set this null hypothesis H0 in our infer workflow using the null argument of the `hypothesize()` function **independence** for hypotheses involving two samples. If the hypotheses involving a single sample, then **point** should be used.
-   The data has not changed yet. This will occur at the upcoming `generate()` step; we're merely setting meta-data for now.

### `generate` replicates

After we `hypothesize()` the null hypothesis, we [`generate()`](https://infer.netlify.app/reference/generate.html) replicates of "shuffled" datasets assuming the null hypothesis is true. We do this by repeating the shuffling exercise several times. The `type` argument determines the method used to create the null distribution. They are three types of rendomisation/permutation methods available. They are:

-   `bootstrap`: A bootstrap sample will be drawn for each replicate, where a sample of size equal to the input sample size is drawn (with replacement) from the input sample data.
-   `permute`: For each replicate, each input value will be randomly reassigned (without replacement) to a new output value in the sample.
-   `draw`: A value will be sampled from a theoretical distribution with parameter p specified in `hypothesize()` for each replicate. This option is currently only applicable for testing on one proportion. This generation type was previously called `simulate`, which has been superseded.

In the code chunk below, we replicates the data 1000 times by using `permute` method.

```{r}
set.seed(1234)
exam_permute <- exam %>% 
  specify(formula = MATHS ~ GENDER) %>% 
  hypothesize(null = "independence") %>% 
  generate(reps = 1000, type = "permute")
exam_permute
```

Thing to learn from the code chunk above.

-   `set.seed()` is used to ensure that the ramdomisation is reproducible.

Note that the resulting data frame has 322,000 rows. This is because we performed permutations for each of the 322 rows 1000 times and 322,000 = 322 x 1000. If you explore the exam_permute data frame with `View()`, you'll notice that the variable replicate indicates which resample each row belongs to. So it has the value 1 322 times, the value 2 322 times, all the way through to the value 1000 322 times.

### `calculate` summary statistics

Now, we are going to calculate the appropriate summary statistic for each of our 1000 shuffles by using [`calculate()`](https://infer.netlify.app/reference/calculate.html) of **infer** package. `stat` argument of `calculate()` will be used to specify the summary statistic used.

In the code chunk below, *"diff in means"* is used.

```{r}
set.seed(1234)
null_distribution_maths <- exam %>% 
  specify(formula = MATHS ~ GENDER) %>% 
  hypothesize(null = "independence") %>% 
  generate(reps = 1000, type = "permute") %>%
  calculate(stat = "diff in means", 
            order = c("Female", "Male"))
null_distribution_maths
```

Note that we have 1000 values of `stat`, each representing one instance of $H0: \hatŒº_f‚àí\hatŒº_m = 0$ in a hypothesized world of no gender difference in maths scores. Observe as well that we chose the name of this data frame carefully: `null_distribution`.

What was the *observed* difference in promotion rates? In other words, what was the *observed test statistic* $H0: \hatŒº_f‚àí\hatŒº_m = 0$. In the code chunk below, we compute this value using the previous `infer` code but with the `hypothesize()` and `generate()` steps removed.

```{r}
obs_diff_means <- exam %>% 
  specify(formula = MATHS ~ GENDER) %>% 
  calculate(stat = "diff in means", 
            order = c("Female", "Male"))
obs_diff_means
```

### `visualize` the p-value

Finally, it comes the verdict or more popularly known as statistical conclusion. In this step, we want to measure how surprised we are by a promotion difference of 1.402012 in a hypothesized universe of there are not different between the maths scores of female and male students. If the observed difference of 1.402012 is highly unlikely, then we would be inclined to reject the validity of our hypothesized universe.

In the code chunk below,

-   [`visualise()`](https://infer.netlify.app/reference/visualize.html) is used to plot the null distribution of our 1000 values of ![](img/image1-6.jpg){width="57"},
-   [`shade_p_value()`](https://infer.netlify.app/reference/visualize.html) function with `obs_stat` argument set to the observed test statistic value we saved in *obs_diff_mean*.

```{r}
visualize(null_distribution_maths, 
          bins = 10) + 
  shade_p_value(obs_stat = obs_diff_means,
                direction = "both")
```

With reference to the figure above, the solid dark red line marks 1.402012. However, what does the shaded-region correspond to? This is the p-value. Recall the definition of the p

> p-value is the probability of obtaining a test statistic just as or more extreme than the observed test statistic assuming the null hypothesis H0 is true.

So judging by the shaded region in the figure above, it seems that the p-value is larger than the 0.05 critical values. Hence, we failed to reject this hypothesized universe, or using statistical language we "*do not have sufficient statistical evident to reject the null hypothesis*".

Oftentimes, we would like to find out what fraction of the null distribution is shaded? In other words, what is the exact value of the p-value? In the code chunk below, `get_p_value()` function with the same arguments as the previous `shade_p_value()` is used to derive the answer for this question.

```{r}
null_distribution_maths %>% 
  get_p_value(obs_stat = obs_diff_means,
              direction = "both")
```

Keeping the definition of a p-value in mind, the probability of observing a difference in mean maths score between female and male students as large as 1.402012 due to sampling variation alone in the null distribution is 0.59 = 59%. Since this p-value is larger than our pre-specified significance level Œ± = 0.05, we failed to reject the null hypothesis $H0: \hatŒº_f‚àí\hatŒº_m = 0$. In other words, this p-value is not sufficiently small to reject our hypothesised universe of the mean maths scores of female and male students are the same. In conclusion, we do not have enough statistical evidence to change our mind in favor of the mean maths scores of female and male students are not the same. 

## Confident interval

In this section, you will learn how to use functions provide by infer package to perform confident interval 

```{r}
exam %>% 
  specify(response = MATHS) %>% 
  calculate(stat = "mean")
```

specify variables

```{r}
exam %>% 
  specify(response = MATHS)
```

```{r}
exam %>% 
  specify(formula = MATHS ~ NULL)
```

generate replicates

```{r}
exam %>% 
  specify(response = MATHS) %>% 
  generate(reps = 1000, type = "bootstrap")
```

calculate summary statistics

```{r}
bootstrap_distribution <- exam %>% 
  specify(response = MATHS) %>% 
  generate(reps = 1000) %>% 
  calculate(stat = "mean")
bootstrap_distribution
```

visualize the results

```{r}
visualize(bootstrap_distribution)
```

```{r}
percentile_ci <- bootstrap_distribution %>% 
  get_confidence_interval(level = 0.95, type = "percentile")
percentile_ci
```

```{r}
visualize(bootstrap_distribution) + 
  shade_confidence_interval(endpoints = percentile_ci)
```

```{r}
#| eval: false
standard_error_ci <- bootstrap_distribution %>%  
  get_confidence_interval(type = "se", point_estimate = x_bar)
```

## Reference

### Randomisation Inferential Statistics

-   [There is still only one test](http://allendowney.blogspot.com/2016/06/there-is-still-only-one-test.html)

-   [Introduction to Modern Statistics](https://openintro-ims.netlify.app/index.html) Chapter 11-22.

-   [Introductory Statistic with Randomization and Simulation](https://openintro-ims.netlify.app/) Chapter 2-4.

### infer

rstudio::conf 2018 [infer: a package for tidy statistical inference](https://www.rstudio.com/resources/rstudioconf-2018/infer-a-package-for-tidy-statistical-inference/)
